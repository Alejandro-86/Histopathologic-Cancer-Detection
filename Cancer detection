# -*- coding: utf-8 -*-
"""AML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NG7cgnXV2ti9bWm90yJlRTB9hy5FlktO

Mount Google drive into Collab Files
"""

# Execute this code block to install dependencies when running on colab
try:
    import torch
except:
    from os.path import exists
    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag
    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())
    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\.\([0-9]*\)\.\([0-9]*\)$/cu\1\2/'
    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'

    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision

try: 
    import torchbearer
except:
    !pip install torchbearer

from google.colab import drive
drive.mount('/content/drive')
from io import BytesIO

try:
  !pip install rarfile
  import rarfile
except:  
  import rarfile
  
try:
  !pip install PIL
  from PIL import Image
except:
  from PIL import Image

rf = rarfile.RarFile('drive/My Drive/Colab Notebooks/Training.rar')
rf.extractall()

rf = rarfile.RarFile('drive/My Drive/Colab Notebooks/Testing.rar')
rf.extractall()

rf = rarfile.RarFile('drive/My Drive/Colab Notebooks/Validation.rar')
rf.extractall()

from PIL import Image
import matplotlib.pyplot as plt
im = Image.open('Testing/0/000020de2aa6193f4c160e398a8edea95b1da598.tif')
plt.imshow(im)
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

# Plot ad hoc data instances
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from torchvision import transforms 
import matplotlib
import matplotlib.pyplot as plt
import numpy

transform = transforms.Compose([
    transforms.Resize((30, 100)),
    transforms.ToTensor()  # convert to tensor
])

train_dataset = ImageFolder("Training", transform)
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)

# generate the first batch
(batch_images, batch_labels) = train_loader.__iter__().__next__()

# plot 4 images
plt.subplot(221).set_title(train_dataset.classes[batch_labels[0]])
plt.imshow(batch_images[0].permute(1, 2, 0), aspect='equal')
plt.subplot(222).set_title(train_dataset.classes[batch_labels[1]])
plt.imshow(batch_images[1].permute(1, 2, 0), aspect='equal')
plt.subplot(223).set_title(train_dataset.classes[batch_labels[2]])
plt.imshow(batch_images[2].permute(1, 2, 0), aspect='equal')
plt.subplot(224).set_title(train_dataset.classes[batch_labels[3]])
plt.imshow(batch_images[3].permute(1, 2, 0), aspect='equal')

# show the plot
plt.show()

# the number of images that will be processed in a single step
batch_size=1024
# the size of the images that we'll learn on - we'll shrink them from the original size for speed
image_size=(30, 100)

transform = transforms.Compose([
    transforms.Resize(image_size),
    transforms.ToTensor()  # convert to tensor
])

train_dataset = ImageFolder("Training", transform)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

val_dataset = ImageFolder("Validation", transform)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)


test_dataset = ImageFolder("Testing", transform)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

import torch 
import torch.nn.functional as F
from torch import nn

# Model Definition
class BetterCNN(nn.Module):
    def __init__(self, n_channels_in, n_classes):
        super(BetterCNN, self).__init__()
        self.conv1 = nn.Conv2d(n_channels_in, 30, (5, 5), padding=0)
        self.conv2 = nn.Conv2d(30, 15, (3, 3), padding=0)
        self.fc1 = nn.Linear(1725, 128)
        self.fc2 = nn.Linear(128, 50)
        self.fc3 = nn.Linear(50, n_classes)
    
    def forward(self, x):
        out = self.conv1(x)
        out = F.relu(out)
        out = F.max_pool2d(out, (2,2))
        out = self.conv2(out)
        out = F.relu(out)
        out = F.max_pool2d(out, (2,2))
        out = F.dropout(out, 0.2)
        out = out.view(out.shape[0], -1)
        out = self.fc1(out)
        out = F.relu(out)
        out = self.fc2(out)
        out = F.relu(out)
        out = self.fc3(out)
        return out

import os
import matplotlib.pyplot as plt
from PIL import Image as PImage

dict_ID_label_0 = {}
dict_ID_label_1 = {}

preprocess_input = transforms.Compose([
                    transforms.CenterCrop(32),
                    transforms.ToTensor(),
                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

path_data_testing_0 = "C:\\Users\\yeganeh\\OneDrive\\Documents\\MSc AI\\Semester2\\AML Coursework\\read_data_Pytorch\\Alex_data\\train\\Testing\\0"
path_data_testing_1 = "C:\\Users\\yeganeh\\OneDrive\\Documents\\MSc AI\\Semester2\\AML Coursework\\read_data_Pytorch\\Alex_data\\train\\Testing\\1"

for root, dirs, files in os.walk(path_data_testing_1):
    for file in files:
        img = PImage.open(path_data_testing_1 + '\\' + file)
        #print(file)
        #plt.imshow(img)
        
        # this give me the labels.
        preds = np.argmax(model(preprocess_input(img).unsqueeze(0)).detach().numpy())
        dict_ID_label_1[file] = preds
        #print(preds)

        
for root, dirs, files in os.walk(path_data_testing_0):
    for file in files:
        img = PImage.open(path_data_testing_0 + '\\' + file)
        #print(file)
        #plt.imshow(img)
        preds = np.argmax(model(preprocess_input(img).unsqueeze(0)).detach().numpy())
        dict_ID_label_0[file] = preds
        #print(preds)
        #break
print(len(dict_ID_label_1))

import torchbearer
from torchbearer import Trial
from torch import optim

model = BetterCNN(3, len(train_dataset.classes))

# define the loss function and the optimiser
loss_function = nn.CrossEntropyLoss()
optimiser = optim.Adam(model.parameters())

device = "cuda:0" if torch.cuda.is_available() else "cpu"
trial = Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)
trial.with_generators(train_loader, val_generator=val_loader, test_generator=test_loader)
trial.run(epochs=10)
results = trial.evaluate(data_key=torchbearer.VALIDATION_DATA)
print()
print(results)

torch.save(model.state_dict(), "./CancerDetection.weights")
from google.colab import files
files.download('CancerDetection.weights')

predictions = trial.predict()
predicted_classes = predictions.argmax(1).cpu()
true_classes = list(x for (_,x) in test_dataset.samples)

from sklearn import metrics
print(metrics.classification_report(true_classes, predicted_classes, target_names=train_dataset.classes))

from torchvision.models import resnet50
from urllib.request import urlopen
from torchvision import transforms 

imagenet_labels = urlopen("https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt").read().decode('utf-8').split("\n")

model = resnet50(pretrained=True)
model.eval()

preprocess_input = transforms.Compose([
            transforms.Resize(224),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225]),
        ])

from PIL import Image as PImage
img_path = 'Testing/0/000020de2aa6193f4c160e398a8edea95b1da598.tif'
img = PImage.open(img_path)

print(preprocess_input(img))
preds = model(preprocess_input(img).unsqueeze(0))

_, indexes = preds.topk(5)
for i in indexes[0]:
    print('Predicted:', imagenet_labels[i])

# Commented out IPython magic to ensure Python compatibility.
import torch 
import torch.nn.functional as F
from torch import nn
# %matplotlib inline

# Plot ad hoc data instances
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from torchvision import transforms 
import matplotlib
import matplotlib.pyplot as plt
import numpy

# the number of images that will be processed in a single step
batch_size=1024
# the size of the images that we'll learn on - we'll shrink them from the original size for speed
image_size=(30, 100)

transform = transforms.Compose([
    transforms.Resize(image_size),
    transforms.ToTensor()  # convert to tensor
])

train_dataset = ImageFolder("Training", transform)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

val_dataset = ImageFolder("Validation", transform)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

test_dataset = ImageFolder("Testing", transform)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

model = resnet50(pretrained=True)
model.avgpool = nn.AdaptiveAvgPool2d((1,1))
model.fc = nn.Linear(2048, len(train_dataset.classes))
model.train()

# Freeze layers by not tracking gradients
n = 1
for param in model.parameters():
    n+=1
    param.requires_grad = True
print('layers',n)
model.fc.weight.requires_grad = True #unfreeze last layer weights
model.fc.bias.requires_grad = True #unfreeze last layer biases

optimiser = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4) #only optimse non-frozen layers

device = "cuda:0" if torch.cuda.is_available() else "cpu"
trial = Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)
trial.with_generators(train_loader, val_generator=val_loader, test_generator=test_loader)
trial.run(epochs=10)
results = trial.evaluate(data_key=torchbearer.TEST_DATA)
print()
print(results)

torch.save(model.state_dict(), "./CancerDetectionResNet50.weights")
from google.colab import files
files.download('CancerDetectionResNet50.weights')

predictions = trial.predict()
predicted_classes = predictions.argmax(1).cpu()
true_classes = list(x for (_,x) in test_dataset.samples)

from sklearn import metrics
print(metrics.classification_report(true_classes, predicted_classes, target_names=train_dataset.classes))
